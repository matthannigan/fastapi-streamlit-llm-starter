services:
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    container_name: llm-starter-backend-${GIT_BRANCH:-main}
    ports:
      - "${BACKEND_PORT:-8000}:8000"
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - AI_MODEL=${AI_MODEL:-gemini-2.0-flash-exp}
      - AI_TEMPERATURE=${AI_TEMPERATURE:-0.7}
      - DEBUG=${DEBUG:-true}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - CORS_ORIGINS=["http://localhost:${FRONTEND_PORT:-8501}", "http://frontend:8501"]
      - REDIS_URL=redis://redis:6379
      - RESILIENCE_PRESET=${RESILIENCE_PRESET:-simple}
      # Phase 4 Cache Preset Configuration - Simplified from 28+ variables to preset-based approach
      # Uses the new cache preset system matching resilience pattern for consistency
      - CACHE_PRESET=${CACHE_PRESET:-development}
      # Essential overrides (only specify if different from preset defaults)
      - CACHE_REDIS_URL=redis://redis:6379
      - ENABLE_AI_CACHE=${ENABLE_AI_CACHE:-true}
      # Advanced customization via JSON (optional - overrides preset defaults)
      # - CACHE_CUSTOM_CONFIG={"default_ttl": 3600, "max_connections": 15}
    volumes:
      - ./backend:/app
      - ./shared:/app/shared
    networks:
      - llm-starter-network
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_started
        required: false  # Make Redis optional
    healthcheck:
      test: ["CMD", "sh", "-c", "curl -f http://localhost:8000/v1/health && curl -f http://localhost:8000/internal/resilience/health && python scripts/health_check_resilience.py"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile
    container_name: llm-starter-frontend-${GIT_BRANCH:-main}
    ports:
      - "${FRONTEND_PORT:-8501}:8501"
    environment:
      - API_BASE_URL=http://backend:8000
      - SHOW_DEBUG_INFO=${SHOW_DEBUG_INFO:-false}
      - MAX_TEXT_LENGTH=${MAX_TEXT_LENGTH:-10000}
    volumes:
      - ./frontend:/app
      - ./shared:/app/shared
    networks:
      - llm-starter-network
    restart: unless-stopped
    depends_on:
      - backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  redis:
    profiles: ["with-cache"]  # Only run when cache is enabled
    image: redis:7-alpine
    container_name: llm-starter-redis-${GIT_BRANCH:-main}
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data_legacy:/data
    networks:
      - llm-starter-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  nginx:
    image: nginx:alpine
    container_name: llm-starter-nginx-${GIT_BRANCH:-main}
    ports:
      - "${NGINX_HTTP_PORT:-80}:80"
      - "${NGINX_HTTPS_PORT:-443}:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    networks:
      - llm-starter-network
    restart: unless-stopped
    depends_on:
      - backend
      - frontend

volumes:
  redis_data_legacy:

networks:
  llm-starter-network:
    driver: bridge