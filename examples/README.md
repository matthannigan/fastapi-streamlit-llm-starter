# FastAPI-Streamlit-LLM Starter Template - Examples

This directory contains comprehensive examples and usage guides for the FastAPI-Streamlit-LLM Starter Template. These examples demonstrate how to use, extend, and test the application.

## ğŸ“ Directory Contents

### Core Examples

- **`basic_usage.py`** - Complete demonstration of all API operations
- **`custom_operation.py`** - Guide for adding custom text processing operations
- **`integration_test.py`** - Comprehensive integration testing suite

### Quick Start

```bash
# Make sure the backend is running
cd backend
python -m uvicorn app.main:app --reload

# In another terminal, run examples
cd examples
python basic_usage.py
```

## ğŸš€ Basic Usage Examples

### `basic_usage.py`

This script demonstrates all core functionality of the FastAPI-Streamlit-LLM Starter Template.

**Features Demonstrated:**
- âœ… API health checks
- ğŸ“‹ Available operations listing
- ğŸ“ Text summarization
- ğŸ˜Š Sentiment analysis
- ğŸ”‘ Key points extraction
- â“ Question generation
- ğŸ’¬ Question & answer
- ğŸš¨ Error handling
- âš¡ Performance benchmarking

**Usage:**
```bash
python basic_usage.py
```

**Sample Output:**
```
ğŸ¤– FastAPI-Streamlit-LLM Starter Template - Basic Usage Examples
============================================================

1ï¸âƒ£ Health Check
--------------
âœ… API Status: healthy
ğŸ¤– AI Model Available: True
ğŸ“… Timestamp: 2024-01-15T10:30:00

2ï¸âƒ£ Available Operations
----------------------
ğŸ“‹ Available operations:
   â€¢ Summarize: Generate a concise summary of the text (Options: max_length)
   â€¢ Sentiment Analysis: Analyze the emotional tone of the text
   â€¢ Key Points: Extract the main points from the text (Options: max_points)
   ...
```

## ğŸ”§ Custom Operations Guide

### `custom_operation.py`

This script provides a step-by-step guide for extending the application with custom text processing operations.

**Custom Operations Demonstrated:**
- ğŸŒ Text translation
- ğŸ“Š Text classification
- ğŸ·ï¸ Named entity extraction
- ğŸ“– Readability analysis

**Usage:**
```bash
python custom_operation.py
```

**What You'll Learn:**
1. How to extend the `ProcessingOperation` enum
2. Adding new processing methods to the backend
3. Updating API endpoints
4. Enhancing the frontend UI
5. Testing and deployment strategies

**Example Custom Operation:**
```python
async def _translate_text(self, text: str, options: Dict[str, Any]) -> str:
    """Translate text to target language."""
    target_language = options.get("target_language", "Spanish")
    
    prompt = f"""
    Translate the following text to {target_language}:
    
    Text: {text}
    
    Translation:
    """
    
    result = await self.agent.run(prompt)
    return result.data.strip()
```

## ğŸ§ª Integration Testing

### `integration_test.py`

Comprehensive testing suite that validates the entire system functionality.

**Test Categories:**
- ğŸ¥ Core functionality tests
- ğŸ“ Text processing operation tests
- ğŸš¨ Error handling tests
- âš¡ Performance tests
- ğŸ”„ Concurrent request tests

**Usage:**
```bash
python integration_test.py
```

**Test Results Example:**
```
ğŸ“Š Test Results:
   Total Tests: 9
   âœ… Passed: 9
   âŒ Failed: 0
   ğŸ“ˆ Success Rate: 100.0%
   â±ï¸  Total Duration: 15.23s
   ğŸ• Average Test Time: 1.69s
```

## ğŸ“‹ Prerequisites

Before running the examples, ensure you have:

1. **Backend Running:**
   ```bash
   cd backend
   python -m uvicorn app.main:app --reload
   ```

2. **Environment Variables:**
   ```bash
   export GEMINI_API_KEY="your-api-key-here"
   ```

3. **Dependencies Installed:**
   ```bash
   pip install httpx asyncio
   ```

## ğŸ¯ Usage Scenarios

### Scenario 1: API Development
Use `basic_usage.py` to understand how to interact with the API programmatically:

```python
from examples.basic_usage import APIClient

async def my_app():
    async with APIClient() as client:
        result = await client.process_text(
            text="Your text here",
            operation="summarize",
            options={"max_length": 100}
        )
        print(result)
```

### Scenario 2: Adding New Features
Follow `custom_operation.py` to add new text processing capabilities:

1. Define new operation in `shared/models.py`
2. Implement processing logic in `backend/app/services/text_processor.py`
3. Update API endpoints in `backend/app/main.py`
4. Enhance frontend UI in `frontend/app/app.py`

### Scenario 3: Quality Assurance
Use `integration_test.py` for comprehensive system validation:

```bash
# Run all tests
python integration_test.py

# Or integrate with pytest
pytest integration_test.py -v
```

## ğŸ” API Reference

### Health Check
```http
GET /health
```

**Response:**
```json
{
  "status": "healthy",
  "ai_model_available": true,
  "timestamp": "2024-01-15T10:30:00"
}
```

### Process Text
```http
POST /process
```

**Request:**
```json
{
  "text": "Your text to process",
  "operation": "summarize",
  "options": {"max_length": 100}
}
```

**Response:**
```json
{
  "operation": "summarize",
  "success": true,
  "result": "Summary of the text...",
  "processing_time": 2.3,
  "metadata": {"word_count": 150}
}
```

### Available Operations
```http
GET /operations
```

**Response:**
```json
{
  "operations": [
    {
      "id": "summarize",
      "name": "Summarize",
      "description": "Generate a concise summary",
      "options": ["max_length"]
    }
  ]
}
```

## ğŸš¨ Error Handling

The examples demonstrate proper error handling for common scenarios:

### Empty Text
```python
# This will raise a validation error
await client.process_text(text="", operation="summarize")
```

### Invalid Operation
```python
# This will raise a 422 error
await client.process_text(text="Valid text", operation="invalid_op")
```

### Missing Required Parameters
```python
# Q&A requires a question
await client.process_text(text="Valid text", operation="qa")  # Missing question
```

## âš¡ Performance Considerations

### Benchmarking Results
Typical performance metrics from `integration_test.py`:

| Operation | Avg Time | Success Rate |
|-----------|----------|--------------|
| Summarize | 2.1s     | 100%         |
| Sentiment | 1.8s     | 100%         |
| Key Points| 2.3s     | 100%         |
| Questions | 2.0s     | 100%         |
| Q&A       | 2.2s     | 100%         |

### Optimization Tips
- Use appropriate `max_length` for summaries
- Batch similar operations when possible
- Implement caching for frequently requested content
- Monitor API rate limits

## ğŸ”§ Troubleshooting

### Common Issues

1. **Connection Refused**
   ```
   Error: Connection refused to localhost:8000
   ```
   **Solution:** Make sure the FastAPI backend is running

2. **API Key Error**
   ```
   Error: AI model not available
   ```
   **Solution:** Set the `GEMINI_API_KEY` environment variable

3. **Timeout Errors**
   ```
   Error: Request timeout
   ```
   **Solution:** Increase timeout in the client or check network connectivity

### Debug Mode
Enable debug logging in the examples:

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ“š Additional Resources

- **Main README:** `../README.md` - Project overview and setup
- **API Documentation:** `http://localhost:8000/docs` - Interactive API docs
- **Frontend:** `http://localhost:8501` - Streamlit interface
- **Backend Tests:** `../backend/tests/` - Unit tests
- **Frontend Tests:** `../frontend/tests/` - UI tests

## ğŸ¤ Contributing

To add new examples:

1. Create a new Python file in this directory
2. Follow the existing code style and documentation format
3. Add comprehensive error handling
4. Include usage instructions in this README
5. Test thoroughly before submitting

## ğŸ“„ License

These examples are part of the FastAPI-Streamlit-LLM Starter Template and are subject to the same license terms as the main project. 